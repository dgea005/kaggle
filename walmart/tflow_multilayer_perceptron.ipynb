{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read in data\n",
    "+ read csvs\n",
    "+ convert to matrices and get index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/model_inputs/X_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/model_inputs/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"data/model_inputs/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_index = y_train.VisitNumber.values\n",
    "y_train_dummies = pd.get_dummies(y_train.drop(\"VisitNumber\",axis=1).TripType).as_matrix()\n",
    "X_train = X_train.drop(['VisitNumber', 'id'], axis=1).as_matrix()\n",
    "X_test = X_test.drop(['VisitNumber', 'id'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95674, 177)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting of train data set to train_ and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(y_train_dummies,1, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in sss:\n",
    "    X_train_, X_val = X_train[train_index], X_train[test_index]\n",
    "    y_train_, y_val = y_train_dummies[train_index], y_train_dummies[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2726690, 177)\n",
      "(2726690, 38)\n",
      "(908922, 177)\n",
      "(908922, 38)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_.shape)\n",
    "print(y_train_.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data set function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class for mini batches with the next_batch function\n",
    "# also gives information about how much of data set is gone through\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, predictors, labels):\n",
    "        self._num_examples = predictors.shape[0]\n",
    "        self._predictors = predictors\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "        \n",
    "    @property\n",
    "    def predictors(self):\n",
    "        return self._predictors\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    \n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    \n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._predictors = self._predictors[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "        return self._predictors[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model specification\n",
    "\n",
    "#\n",
    "# mlp \n",
    "#\n",
    "\n",
    "# Parameters\n",
    "\n",
    "#Network Parameters\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 128\n",
    "\n",
    "n_input = X_train_.shape[1]  # total number of input variables\n",
    "n_classes = y_train_.shape[1] # total number of classes\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# drop out\n",
    "keep_prob_l1 = tf.placeholder(\"float\")\n",
    "keep_prob_l2 = tf.placeholder(\"float\")\n",
    "\n",
    "\n",
    "\n",
    "def multilayer_perceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.tanh(tf.matmul(_X, _weights['h1']) + _biases['b1']) \n",
    "    layer_1_drop = tf.nn.dropout(layer_1, keep_prob_l1)\n",
    "    layer_2 = tf.nn.tanh(tf.matmul(layer_1_drop, _weights['h2']) + _biases['b2'])\n",
    "    layer_2_drop = tf.nn.dropout(layer_2, keep_prob_l2)\n",
    "    return tf.matmul(layer_2_drop, weights['out']) + biases['out']\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "py_x = multilayer_perceptron(X, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y)) # compute mean cross entropy (softmax is applied internally)\n",
    "train_op = tf.train.RMSPropOptimizer(learning_rate=0.001, decay=0.8).minimize(cost) # construct optimizer\n",
    "model_output = tf.nn.softmax(py_x)\n",
    "\n",
    "data_sets = DataSet(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, softmax cross entropy 21.0316\n",
      "step 5000, softmax cross entropy 1.80816\n",
      "step 10000, softmax cross entropy 0.966205\n",
      "step 15000, softmax cross entropy 1.11696\n",
      "step 20000, softmax cross entropy 0.95208\n",
      "step 25000, softmax cross entropy 0.83262\n",
      "step 30000, softmax cross entropy 0.843167\n",
      "step 35000, softmax cross entropy 1.0545\n",
      "step 40000, softmax cross entropy 0.843817\n",
      "step 45000, softmax cross entropy 0.799078\n",
      "step 50000, softmax cross entropy 0.852599\n",
      "step 55000, softmax cross entropy 0.827224\n",
      "step 60000, softmax cross entropy 0.759751\n",
      "step 65000, softmax cross entropy 0.695444\n",
      "step 70000, softmax cross entropy 0.79962\n",
      "step 75000, softmax cross entropy 0.718751\n",
      "step 80000, softmax cross entropy 0.795504\n",
      "step 85000, softmax cross entropy 0.703262\n",
      "step 90000, softmax cross entropy 0.839027\n",
      "step 95000, softmax cross entropy 0.67068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73592794632339409"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run ops / training steps here\n",
    "batch_size = 200\n",
    "\n",
    "\n",
    "for i in range(100000):\n",
    "    batch = data_sets.next_batch(batch_size)\n",
    "    if i%5000 == 0:\n",
    "        train_accuracy = cost.eval(feed_dict={X: batch[0], \n",
    "                                              Y: batch[1], \n",
    "                                              keep_prob_l1: 1.0, \n",
    "                                              keep_prob_l2: 1.0})\n",
    "        print(\"step %d, softmax cross entropy %g\"%(i, train_accuracy))\n",
    "    train_op.run(feed_dict={X: batch[0], \n",
    "                            Y: batch[1], \n",
    "                            keep_prob_l1: 0.8, \n",
    "                            keep_prob_l2:0.8})\n",
    "    \n",
    "       \n",
    "y_test_pred = sess.run(model_output,feed_dict={X: X_val, \n",
    "                                               keep_prob_l1: 1.0, \n",
    "                                               keep_prob_l2: 1.0})\n",
    "log_loss(y_true=y_val, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
